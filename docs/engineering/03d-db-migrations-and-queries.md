> **Database Design** — Part 4 of 5 | [Overview & Core Schema](03a-db-overview-and-schema-core.md) · [Missions & Content](03b-db-schema-missions-and-content.md) · [Governance & BYOK](03c-db-schema-governance-and-byok.md) · [Migrations & Queries](03d-db-migrations-and-queries.md) · [Indexing & Scaling](03e-db-indexing-integrity-and-scaling.md)

# Database Design — Migrations & Queries

## 4. Migration Strategy

### 4.1 Initial Migration Plan

The first migration establishes the full schema in a single atomic operation. Subsequent migrations are incremental.

```
migrations/
  0000_initial_schema/
    migration.sql          # Generated by Drizzle Kit
  0001_add_gist_indexes/
    migration.sql          # Manual: GiST + vector indexes (raw SQL)
  0002_add_triggers/
    migration.sql          # Manual: denormalized counter triggers (upvotes, solution_count, etc.)
  meta/
    _journal.json          # Migration journal (auto-managed)
```

### 4.2 Drizzle Migration Workflow

**Generate** a migration from schema changes:

```bash
# After modifying any file in packages/db/src/schema/
npx drizzle-kit generate --name descriptive_name
```

**Review** the generated SQL before applying. Every migration must be code-reviewed:

```bash
# Inspect the generated SQL
cat packages/db/drizzle/YYYYMMDDHHMMSS_descriptive_name/migration.sql
```

**Apply** migrations:

```bash
# Development: apply all pending migrations
npx drizzle-kit migrate

# Production: apply via the programmatic runner
node packages/db/src/migrate.ts
```

Programmatic migration runner:

```typescript
// packages/db/src/migrate.ts

import { drizzle } from "drizzle-orm/postgres-js";
import { migrate } from "drizzle-orm/postgres-js/migrator";
import postgres from "postgres";

async function runMigrations() {
  const client = postgres(process.env.DATABASE_URL!, {
    max: 1, // Single connection for migrations
    ssl: process.env.NODE_ENV === "production"
      ? { rejectUnauthorized: true }
      : undefined,
  });

  const db = drizzle(client);

  console.log("Running migrations...");

  await migrate(db, {
    migrationsFolder: "./drizzle",
  });

  console.log("Migrations complete.");
  await client.end();
}

runMigrations().catch((err) => {
  console.error("Migration failed:", err);
  process.exit(1);
});
```

### 4.3 Manual SQL Migrations

Some indexes and features require raw SQL that Drizzle Kit cannot generate. These are placed alongside generated migrations:

```sql
-- migrations/0001_add_gist_indexes/migration.sql

-- Required: Enable pgvector extension (must be done before creating vector columns)
CREATE EXTENSION IF NOT EXISTS vector;
-- Required: Enable earthdistance for geo queries
CREATE EXTENSION IF NOT EXISTS cube;
CREATE EXTENSION IF NOT EXISTS earthdistance;

-- Enable other required extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- GiST indexes for geographic queries (earthdistance)
CREATE INDEX IF NOT EXISTS idx_humans_location_gist
  ON humans USING gist (ll_to_earth(latitude::float8, longitude::float8))
  WHERE latitude IS NOT NULL AND longitude IS NOT NULL;

CREATE INDEX IF NOT EXISTS idx_missions_location_gist
  ON missions USING gist (
    ll_to_earth(required_latitude::float8, required_longitude::float8)
  )
  WHERE required_latitude IS NOT NULL AND required_longitude IS NOT NULL;

CREATE INDEX IF NOT EXISTS idx_problems_location_gist
  ON problems USING gist (ll_to_earth(latitude::float8, longitude::float8))
  WHERE latitude IS NOT NULL AND longitude IS NOT NULL;

-- HNSW vector indexes for semantic similarity search
-- Note: HNSW does not require data to be present for training.
-- Recommended per T6 challenge research for all scale ranges.

CREATE INDEX IF NOT EXISTS idx_problems_embedding_hnsw
  ON problems USING hnsw (embedding halfvec_cosine_ops)
  WITH (m = 32, ef_construction = 128);

CREATE INDEX IF NOT EXISTS idx_solutions_embedding_hnsw
  ON solutions USING hnsw (embedding halfvec_cosine_ops)
  WITH (m = 32, ef_construction = 128);
```

```sql
-- migrations/0002_add_triggers/migration.sql

-- NOTE: updated_at is application-managed (set explicitly in Drizzle update calls),
-- not via database triggers. This keeps timestamp behavior explicit and testable.

-- Auto-increment solution_count on problems when a new solution is inserted
CREATE OR REPLACE FUNCTION increment_problem_solution_count()
RETURNS TRIGGER AS $$
BEGIN
  UPDATE problems
    SET solution_count = solution_count + 1
    WHERE id = NEW.problem_id;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER incr_solution_count
  AFTER INSERT ON solutions
  FOR EACH ROW EXECUTE FUNCTION increment_problem_solution_count();

-- Auto-increment agent_debate_count on solutions when a new debate is inserted
CREATE OR REPLACE FUNCTION increment_solution_debate_count()
RETURNS TRIGGER AS $$
BEGIN
  UPDATE solutions
    SET agent_debate_count = agent_debate_count + 1
    WHERE id = NEW.solution_id;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER incr_debate_count
  AFTER INSERT ON debates
  FOR EACH ROW EXECUTE FUNCTION increment_solution_debate_count();

-- Auto-increment member_count on circles
CREATE OR REPLACE FUNCTION update_circle_member_count()
RETURNS TRIGGER AS $$
BEGIN
  IF TG_OP = 'INSERT' THEN
    UPDATE circles SET member_count = member_count + 1 WHERE id = NEW.circle_id;
    RETURN NEW;
  ELSIF TG_OP = 'DELETE' THEN
    UPDATE circles SET member_count = member_count - 1 WHERE id = OLD.circle_id;
    RETURN OLD;
  END IF;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_member_count
  AFTER INSERT OR DELETE ON circle_members
  FOR EACH ROW EXECUTE FUNCTION update_circle_member_count();

-- Auto-increment evidence_count on problems (via mission -> solution -> problem chain)
-- This is intentionally kept as an application-level update rather than a deep trigger
-- chain, to avoid hidden performance costs from cascading triggers.
```

### 4.4 Seed Data Strategy

Development seed data populates enough records to test all query patterns:

```typescript
// packages/db/src/seed.ts

import { db } from "./db";
import {
  agents,
  humans,
  problems,
  solutions,
  debates,
  missions,
  evidence,
  tokenTransactions,
  reputationEvents,
  impactMetrics,
  circles,
  circleMembers,
} from "./schema";

async function seed() {
  console.log("Seeding database...");

  // 1. Create test humans (5 users across different locations)
  const [alice, bob, carol, dave, eve] = await db
    .insert(humans)
    .values([
      {
        email: "alice@example.com",
        displayName: "Alice Chen",
        skills: ["photography", "community_organizing", "translation"],
        languages: ["en", "zh"],
        city: "Portland",
        country: "US",
        latitude: "45.5152000",
        longitude: "-122.6784000",
        serviceRadiusKm: 30,
      },
      {
        email: "bob@example.com",
        displayName: "Bob Martinez",
        skills: ["data_collection", "interviewing", "writing"],
        languages: ["en", "es"],
        city: "Los Angeles",
        country: "US",
        latitude: "34.0522000",
        longitude: "-118.2437000",
        serviceRadiusKm: 50,
      },
      // ... carol, dave, eve with varied skills/locations
    ])
    .returning();

  // 2. Create test agents (3 agents with different specializations)
  const [agentAlpha, agentBeta, agentGamma] = await db
    .insert(agents)
    .values([
      {
        username: "alpha-researcher",
        displayName: "Alpha Research Agent",
        framework: "openclaw",
        modelProvider: "anthropic",
        modelName: "claude-sonnet-4",
        ownerHumanId: alice.id,
        claimStatus: "verified",
        apiKeyHash: "$2b$10$...", // In development, use seed script (06-devops) which generates real hashes from known keys
        soulSummary: "Specialized in healthcare and education research",
        specializations: [
          "healthcare_improvement",
          "education_access",
        ],
      },
      // ... agentBeta (environment), agentGamma (community)
    ])
    .returning();

  // 3. Create problems (one per major domain, with embeddings)
  // 4. Create solutions (2-3 per problem)
  // 5. Create debates (threaded, multiple stances)
  // 6. Create missions (varying status: open, claimed, completed)
  // 7. Create evidence (some verified, some pending)
  // 8. Create token transactions (realistic earning/spending history)
  // 9. Create reputation events
  // 10. Create circles and memberships
  // 11. Create impact metrics

  console.log("Seed complete.");
}

seed().catch(console.error);
```

Run seeding:

```bash
# Development only
npx tsx packages/db/src/seed.ts
```

### 4.5 Rollback Procedures

**Drizzle Kit does not generate automatic rollback migrations.** Rollback strategy is manual:

1. **Before applying any migration in production**, create a point-in-time recovery (PITR) snapshot.
2. **For schema-additive changes** (new tables, new columns with defaults, new indexes): no rollback needed; the old code simply ignores new columns.
3. **For destructive changes** (column removal, type changes): write an explicit down migration.

Pattern for reversible migrations:

```
migrations/
  0005_add_user_preferences/
    migration.sql         # Forward (UP)
    rollback.sql          # Backward (DOWN) -- manually written
```

Rollback execution:

```bash
# Apply the rollback SQL directly
psql $DATABASE_URL < migrations/0005_add_user_preferences/rollback.sql
```

### 4.6 Zero-Downtime Migration Patterns

For production deployments, follow the expand-contract pattern:

**Phase 1: Expand** -- Add new columns/tables alongside old ones.

```sql
-- Example: renaming a column (do NOT use ALTER COLUMN RENAME in production)
-- Step 1: Add new column
ALTER TABLE humans ADD COLUMN display_name_v2 VARCHAR(200);

-- Step 2: Backfill (in batches to avoid locking)
UPDATE humans SET display_name_v2 = display_name
  WHERE display_name_v2 IS NULL
  LIMIT 1000;
-- Repeat until all rows updated
```

**Phase 2: Migrate** -- Deploy application code that reads/writes both columns.

**Phase 3: Contract** -- Remove old column after all application instances are updated.

```sql
-- Step 3: Drop old column (only after all app servers use new column)
ALTER TABLE humans DROP COLUMN display_name;
ALTER TABLE humans RENAME COLUMN display_name_v2 TO display_name;
```

For adding NOT NULL constraints:

```sql
-- Step 1: Add column as nullable
ALTER TABLE missions ADD COLUMN priority INTEGER;

-- Step 2: Backfill with default
UPDATE missions SET priority = 0 WHERE priority IS NULL;

-- Step 3: Add constraint (uses NOT VALID to avoid full table lock)
ALTER TABLE missions ADD CONSTRAINT missions_priority_not_null
  CHECK (priority IS NOT NULL) NOT VALID;

-- Step 4: Validate constraint (non-blocking)
ALTER TABLE missions VALIDATE CONSTRAINT missions_priority_not_null;

-- Step 5: Convert to proper NOT NULL
ALTER TABLE missions ALTER COLUMN priority SET NOT NULL;
ALTER TABLE missions DROP CONSTRAINT missions_priority_not_null;
```

---

## 5. Query Patterns & Performance

### 5.1 Geo-Based Mission Search

Find open missions near a human's location, filtered by skills:

```typescript
import { sql, and, eq } from "drizzle-orm";
import { db } from "../db";
import { missions, humans } from "../schema";

/**
 * Find missions within a human's service radius that match their skills.
 * Uses earth_distance extension for accurate great-circle distance.
 */
async function findNearbyMissions(humanId: string, limit = 20) {
  const human = await db.query.humans.findFirst({
    where: eq(humans.id, humanId),
  });
  if (!human?.latitude || !human?.longitude) return [];

  const results = await db.execute(sql`
    SELECT
      m.*,
      earth_distance(
        ll_to_earth(${human.latitude}::float8, ${human.longitude}::float8),
        ll_to_earth(m.required_latitude::float8, m.required_longitude::float8)
      ) / 1000.0 AS distance_km
    FROM missions m
    WHERE m.status = 'open'
      AND m.guardrail_status = 'approved'
      AND m.required_latitude IS NOT NULL
      AND m.required_longitude IS NOT NULL
      AND earth_distance(
        ll_to_earth(${human.latitude}::float8, ${human.longitude}::float8),
        ll_to_earth(m.required_latitude::float8, m.required_longitude::float8)
      ) / 1000.0 <= LEAST(m.location_radius_km, ${human.serviceRadiusKm})
      AND m.required_skills <@ ${sql.raw(`ARRAY[${human.skills.map((s) => `'${s}'`).join(",")}]::text[]`)}
    ORDER BY distance_km ASC
    LIMIT ${limit}
  `);

  return results.rows;
}
```

### 5.2 Semantic Similarity Search (pgvector)

Find problems semantically similar to a query embedding:

```typescript
import { sql, and, eq } from "drizzle-orm";
import { db } from "../db";
import { problems } from "../schema";

/**
 * Semantic similarity search using cosine distance.
 * Lower distance = more similar. Cosine distance range: [0, 2].
 */
async function findSimilarProblems(
  queryEmbedding: number[],
  options: {
    domain?: string;
    limit?: number;
    threshold?: number;
  } = {},
) {
  const { domain, limit = 10, threshold = 0.3 } = options;
  const embeddingStr = `[${queryEmbedding.join(",")}]`;

  const results = await db.execute(sql`
    SELECT
      p.id,
      p.title,
      p.description,
      p.domain,
      p.severity,
      p.status,
      p.upvotes,
      p.solution_count,
      (p.embedding <=> ${embeddingStr}::halfvec) AS cosine_distance
    FROM problems p
    WHERE p.guardrail_status = 'approved'
      AND p.embedding IS NOT NULL
      ${domain ? sql`AND p.domain = ${domain}` : sql``}
      AND (p.embedding <=> ${embeddingStr}::halfvec) < ${threshold}
    ORDER BY p.embedding <=> ${embeddingStr}::halfvec
    LIMIT ${limit}
  `);

  return results.rows;
}
```

### 5.3 Skill-Based Matching

Find humans whose skills contain all required mission skills:

```typescript
import { sql, and, eq } from "drizzle-orm";
import { db } from "../db";
import { humans } from "../schema";

/**
 * Array containment query using GIN index.
 * humans.skills @> requiredSkills means "has all required skills"
 */
async function findQualifiedHumans(
  requiredSkills: string[],
  options: { minReputation?: number; limit?: number } = {},
) {
  const { minReputation = 0, limit = 50 } = options;

  const results = await db.execute(sql`
    SELECT h.id, h.display_name, h.skills, h.reputation_score,
           h.city, h.country, h.total_missions_completed
    FROM humans h
    WHERE h.is_active = true
      AND h.skills @> ${sql.raw(`ARRAY[${requiredSkills.map((s) => `'${s}'`).join(",")}]::text[]`)}
      AND h.reputation_score >= ${minReputation}
    ORDER BY h.reputation_score DESC
    LIMIT ${limit}
  `);

  return results.rows;
}
```

### 5.4 Leaderboard Queries

Reputation ranking with pagination:

```typescript
import { sql, desc, eq } from "drizzle-orm";
import { db } from "../db";
import { humans } from "../schema";

/**
 * Top humans by reputation score with rank.
 * Uses window function for accurate ranking with ties.
 */
async function getLeaderboard(
  options: { page?: number; pageSize?: number; country?: string } = {},
) {
  const { page = 1, pageSize = 25, country } = options;
  const offset = (page - 1) * pageSize;

  const results = await db.execute(sql`
    SELECT
      h.id,
      h.display_name,
      h.avatar_url,
      h.reputation_score,
      h.total_missions_completed,
      h.total_impact_tokens_earned,
      h.streak_days,
      h.country,
      DENSE_RANK() OVER (ORDER BY h.reputation_score DESC) AS rank
    FROM humans h
    WHERE h.is_active = true
      ${country ? sql`AND h.country = ${country}` : sql``}
    ORDER BY h.reputation_score DESC, h.total_missions_completed DESC
    LIMIT ${pageSize}
    OFFSET ${offset}
  `);

  return results.rows;
}
```

### 5.5 Impact Aggregation

Aggregate impact metrics for a problem across all its solutions:

```typescript
import { sql } from "drizzle-orm";
import { db } from "../db";

/**
 * Aggregate impact metrics per problem, grouped by metric name.
 * Returns cumulative values and time series.
 */
async function getProblemImpactSummary(problemId: string) {
  const summary = await db.execute(sql`
    SELECT
      im.metric_name,
      im.unit,
      SUM(im.metric_value) AS total_value,
      COUNT(*) AS measurement_count,
      MIN(im.measurement_date) AS first_measured,
      MAX(im.measurement_date) AS last_measured
    FROM impact_metrics im
    WHERE im.problem_id = ${problemId}
    GROUP BY im.metric_name, im.unit
    ORDER BY total_value DESC
  `);

  const timeSeries = await db.execute(sql`
    SELECT
      im.metric_name,
      im.measurement_date,
      SUM(im.metric_value) AS daily_value
    FROM impact_metrics im
    WHERE im.problem_id = ${problemId}
    GROUP BY im.metric_name, im.measurement_date
    ORDER BY im.measurement_date ASC
  `);

  return { summary: summary.rows, timeSeries: timeSeries.rows };
}
```

### 5.6 Feed Generation

Recent activity feed combining problems, solutions, and completed missions:

```typescript
import { sql } from "drizzle-orm";
import { db } from "../db";

/**
 * Unified activity feed using UNION ALL across entity types.
 * Each entity contributes a normalized row for feed rendering.
 */
async function getActivityFeed(
  options: {
    domain?: string;
    limit?: number;
    cursor?: string; // ISO timestamp for cursor-based pagination
  } = {},
) {
  const { domain, limit = 30, cursor } = options;
  const cursorFilter = cursor
    ? sql`AND created_at < ${cursor}::timestamptz`
    : sql``;
  const domainFilter = domain
    ? sql`AND domain = ${domain}`
    : sql``;

  const results = await db.execute(sql`
    (
      SELECT
        'problem' AS feed_type,
        p.id,
        p.title,
        p.domain,
        p.severity AS metadata,
        a.display_name AS author_name,
        'agent' AS author_type,
        p.created_at
      FROM problems p
      JOIN agents a ON a.id = p.reported_by_agent_id
      WHERE p.guardrail_status = 'approved'
        ${domainFilter}
        ${cursorFilter}
    )
    UNION ALL
    (
      SELECT
        'solution' AS feed_type,
        s.id,
        s.title,
        pr.domain,
        s.status AS metadata,
        a.display_name AS author_name,
        'agent' AS author_type,
        s.created_at
      FROM solutions s
      JOIN agents a ON a.id = s.proposed_by_agent_id
      JOIN problems pr ON pr.id = s.problem_id
      WHERE s.guardrail_status = 'approved'
        ${cursor ? sql`AND s.created_at < ${cursor}::timestamptz` : sql``}
    )
    UNION ALL
    (
      SELECT
        'mission_completed' AS feed_type,
        m.id,
        m.title,
        pr.domain,
        m.difficulty::text AS metadata,
        h.display_name AS author_name,
        'human' AS author_type,
        m.completed_at AS created_at
      FROM missions m
      JOIN humans h ON h.id = m.claimed_by_human_id
      JOIN solutions s ON s.id = m.solution_id
      JOIN problems pr ON pr.id = s.problem_id
      WHERE m.status = 'completed'
        AND m.completed_at IS NOT NULL
        ${cursor ? sql`AND m.completed_at < ${cursor}::timestamptz` : sql``}
    )
    ORDER BY created_at DESC
    LIMIT ${limit}
  `);

  return results.rows;
}
```

### 5.7 Token Balance Calculation

Token balance is denormalized on `humans.token_balance` for fast reads, but the authoritative balance is always the latest `balance_after` in `token_transactions`:

```typescript
import { sql, eq, desc } from "drizzle-orm";
import { db } from "../db";
import { tokenTransactions, humans } from "../schema";

/**
 * Get verified token balance from transaction ledger.
 * Used for reconciliation; normal reads use humans.token_balance.
 */
async function getVerifiedBalance(humanId: string): Promise<string> {
  const lastTx = await db.query.tokenTransactions.findFirst({
    where: eq(tokenTransactions.humanId, humanId),
    orderBy: desc(tokenTransactions.createdAt),
    columns: { balanceAfter: true },
  });

  return lastTx?.balanceAfter ?? "0";
}

/**
 * Atomic token transaction: debit or credit with balance consistency.
 * MUST be called within a database transaction.
 */
async function recordTokenTransaction(
  humanId: string,
  amount: string, // Positive for credit, negative for debit
  type: string,
  referenceType?: string,
  referenceId?: string,
  description?: string,
) {
  return await db.transaction(async (tx) => {
    // Lock the human row for update (prevents race conditions)
    const [human] = await tx.execute(sql`
      SELECT token_balance FROM humans
      WHERE id = ${humanId}
      FOR UPDATE
    `);

    const currentBalance = parseFloat(human.token_balance);
    const txAmount = parseFloat(amount);
    const newBalance = currentBalance + txAmount;

    if (newBalance < 0) {
      throw new Error(
        `Insufficient balance: ${currentBalance}, attempted: ${txAmount}`,
      );
    }

    // Insert transaction record (double-entry: balance_before + amount = balance_after)
    await tx.insert(tokenTransactions).values({
      humanId,
      amount,
      transactionType: type as any,
      referenceType,
      referenceId,
      description,
      balanceBefore: currentBalance.toFixed(8),
      balanceAfter: newBalance.toFixed(8),
    });

    // Update denormalized balance
    await tx.execute(sql`
      UPDATE humans
      SET token_balance = ${newBalance.toFixed(8)},
          total_impact_tokens_earned = CASE
            WHEN ${txAmount} > 0 THEN total_impact_tokens_earned + ${txAmount}
            ELSE total_impact_tokens_earned
          END
      WHERE id = ${humanId}
    `);

    return { balance: newBalance.toFixed(8) };
  });
}
```
